{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "from scipy.optimize import minimize\n",
    "import api"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 1 -- Define tickers and time period\n",
    "## How can i create a portfolio with the highest risk adjusted return?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the list of tickers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tickers = ['SPY', 'BND','GLD','QQQ','VTI']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "end_date = datetime.today()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set start date 5 years ago"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "start_date = end_date - timedelta(days=365*5)\n",
    "start_date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 2: download Adjusted Close Prices\n",
    "\n",
    "## Create an empty DataFrame to store the adj close prices\n",
    "\n",
    "### Adj close is more representative of overall returns as they include dividents and stock splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj_close_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download close price for each of the tickers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "for ticker in tickers:\n",
    "    data = yf.download(ticker, start=start_date, end=end_date, auto_adjust=False)\n",
    "    adj_close_df[ticker] = data['Adj Close']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "# Check adj close_df\n",
    "print(adj_close_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 3: Calculate Log normal returns for each ticker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "log_returns_df = np.log(adj_close_df / adj_close_df.shift(1))\n",
    "# Check log returns\n",
    "print(log_returns_df.head())\n",
    "print(log_returns_df.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drop missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "log_returns_df = log_returns_df.dropna()\n",
    "log_returns_df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 4: Calculate Covariance Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "cov_matrix = log_returns_df.cov() * 252  # Annualize the covariance matrix\n",
    "cov_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 5: Portfolio performance metrics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Portfolio Standard deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standard_deviation(weights, cov_matrix):\n",
    "    \"\"\"\n",
    "    Calculate the portfolio standard deviation.\n",
    "    \"\"\"\n",
    "    return np.sqrt(np.dot(weights.T, np.dot(cov_matrix, weights)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Expected Return\n",
    "\n",
    "Assuming expected returns are similar to historical returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expected_return(weights, log_returns_df):\n",
    "    \"\"\"\n",
    "    Calculate the expected portfolio return.\n",
    "    \"\"\"\n",
    "    return np.sum(log_returns_df.mean() * weights) * 252  # Annualize the return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Sharpe Ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sharpe_ratio(weights, log_returns_df, cov_matrix, risk_free_rate):\n",
    "    \"\"\"\n",
    "    Calculate the Sharpe Ratio of the portfolio.\n",
    "    \"\"\"\n",
    "    return(expected_return (weights, log_returns_df) - risk_free_rate) / standard_deviation(weights, cov_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Sortino Ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sortino_ratio(weights, log_returns_df, cov_matrix, risk_free_rate):\n",
    "    \"\"\"\n",
    "    Calculate the Sortino Ratio of the portfolio.\n",
    "    \"\"\"\n",
    "    downside_returns = log_returns_df[log_returns_df < 0]\n",
    "    downside_deviation = np.sqrt(np.dot(weights.T, np.dot(downside_returns.cov() * 252, weights)))\n",
    "    return (expected_return(weights, log_returns_df) - risk_free_rate) / downside_deviation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 6: Portfolio Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Risk Free Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_risk_free_rate(api_key):\n",
    "    \"\"\"\n",
    "    Fetch the risk-free rate from FRED.\n",
    "    \"\"\"\n",
    "    import requests\n",
    "    #using the 10-year Treasury yield as a proxy for the risk-free rate\n",
    "    url = f'https://api.stlouisfed.org/fred/series/observations?series_id=GS10&api_key={api.FRED_API_KEY}&file_type=json'\n",
    "    response = requests.get(url)\n",
    "    data = response.json()\n",
    "    rate = float(data['observations'][-1]['value']) / 100  # Convert percentage to decimal\n",
    "    return rate\n",
    "risk_free_rate = get_risk_free_rate(fred_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "risk_free_rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Function to minimize\n",
    "\n",
    "### Negative sharpe ratio\n",
    "\n",
    "we use the scipy.optimize.minimize() function to minimize the value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def negative_sharpe_ratio(weights, log_returns_df, cov_matrix, risk_free_rate):\n",
    "    \"\"\"\n",
    "    Objective function to minimize: negative Sharpe Ratio.\n",
    "    \"\"\"\n",
    "    return -sharpe_ratio(weights, log_returns_df, cov_matrix, risk_free_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Constrains and Bounds\n",
    "\n",
    "constrains and conditions that must be met by the solution during the optimization process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "constrains = ({'type': 'eq', 'fun': lambda weights: np.sum(weights) - 1})  # Weights must sum to 1\n",
    "\n",
    "bounds = [(0, .5) for _ in range(len(tickers))]  # Weights must be between 0 and 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Initial weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# can be changed to inputs by user\n",
    "\n",
    "initial_weights = np.array([1/len(tickers)] * len(tickers))  # Equal weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Oprimize the weights to maximize the the sharpe ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimized_result = minimize(negative_sharpe_ratio, initial_weights, args = (log_returns_df, cov_matrix, risk_free_rate),\n",
    "                            method='SLSQP', bounds=bounds, constraints=constrains)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get optimal weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimal_weights = optimized_result.x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 7: Analyze the Optimal Portfolio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display analytics of the optimal portfolio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "print(optimal_weights)\n",
    "for ticker, weight in zip(tickers, optimal_weights):\n",
    "    print(f\"{ticker}: {weight:.2%}\")\n",
    "print()\n",
    "\n",
    "optimal_portfolio_return = expected_return(optimal_weights, log_returns_df)\n",
    "optimal_portfolio_volatility = standard_deviation(optimal_weights, cov_matrix)\n",
    "optimal_portfolio_sharpe = sharpe_ratio(optimal_weights, log_returns_df, cov_matrix, risk_free_rate)\n",
    "\n",
    "print(f\"expected annual return: {optimal_portfolio_return: 4f}\")\n",
    "print(f\"expected volatility: {optimal_portfolio_volatility: 4f}\")\n",
    "print(f\"expected Sharpe Ratio: {optimal_portfolio_sharpe: 4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display Final Portfolio as a Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "# display as a pie chart using matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.pie(optimal_weights, labels=tickers, autopct='%1.1f%%', startangle=140)\n",
    "plt.title('Optimal Portfolio Allocation')\n",
    "plt.axis('equal')  # Equal aspect ratio ensures that pie chart is a circle.\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
